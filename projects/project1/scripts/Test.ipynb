{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCML PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "print(tX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(tX):\n",
    "    nullValue = -999\n",
    "    tX[tX==nullValue] = 0\n",
    "    m = np.mean(tX, axis=0)\n",
    "    tX_centered = tX - m\n",
    "\n",
    "    tX_centered[tX_centered==0] = float('nan')\n",
    "    tX_std= np.nanstd(tX_centered, axis=0)\n",
    "    tX_centered[tX_centered==float('nan')] = 0\n",
    "    normalized = tX_centered / tX_std\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test normalize function\n",
    "#print(tX)\n",
    "#norm = normalize(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probably useless\n",
    "\n",
    "def removeNullColumns(tX, threshold):\n",
    "    nullValue = -999\n",
    "    rows, columns = tX.shape\n",
    "    toDelete = []\n",
    "    \n",
    "    for column in range(0, columns):\n",
    "        xi = tX[column]\n",
    "        xi[xi == nullValue] = np.nan\n",
    "        m = np.nansum(xi)\n",
    "        if (m / rows > threshold):\n",
    "            toDelete.append(column)\n",
    "            \n",
    "    print(\"Columns deleted: \", toDelete)\n",
    "    new = np.delete(tX, toDelete)  \n",
    "    print(\"new\", new.shape)\n",
    "    return new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probably useless too\n",
    "\n",
    "def replaceNullValue(tX):\n",
    "    nullValue = -999\n",
    "    rows, columns = tX.shape\n",
    "    x = tX\n",
    "    print(\"old\", x.shape)\n",
    "    \n",
    "    for column in range(0, columns):\n",
    "        xi = x[column]\n",
    "        xi[xi == nullValue] = np.nan\n",
    "        mean = np.mean(xi)\n",
    "        nanIndex = np.where(np.isnan(xi))\n",
    "        xi[nanIndex] = mean\n",
    "        x[column] = xi\n",
    "    return tX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from least_squares import *\n",
    "from regression import *\n",
    "\n",
    "def learn_with(method, y, tx, gamma=0.1, max_iters=5, lambda_=0.1):\n",
    "    if method == 'least_squares':\n",
    "        return least_squares(y, tx)\n",
    "    \n",
    "    if method == 'least_square_GD': \n",
    "        return least_squares_GD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'least_square_SGD': \n",
    "        return least_squares_SGD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'logistic_regression': \n",
    "        return logistic_regression(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'pen_logistic_regression': \n",
    "        return pen_logisitic_regression(y, tx, lambda_, gamma, max_iters)\n",
    "    \n",
    "    if method == 'ridge_regression': \n",
    "        return ridge_regression(y, tx, lambda_)\n",
    "    \n",
    "    return least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 30)\n",
      "(31,)\n"
     ]
    }
   ],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "normalizedtX = normalize(tX)\n",
    "print(normalizedtX.shape)\n",
    "x = np.hstack((np.ones((normalizedtX.shape[0],1)), normalizedtX))\n",
    "loss, weights = learn_with(\"least_square_GD\", y, x)\n",
    "print(weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "print(tX_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare tX_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tXTe = normalize(tX_test)\n",
    "tXTe = np.hstack((np.ones((tX_test.shape[0],1)), tXTe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/out.csv'\n",
    "\n",
    "y_pred = predict_labels(weights, tXTe)\n",
    "\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
