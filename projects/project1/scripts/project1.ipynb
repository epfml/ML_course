{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "def prepare(x):\n",
    "    \"\"\"\n",
    "    Prepare the data by standardizing and replacing unused \n",
    "    values (-999) by the mean of their columns such that they\n",
    "    don't affect the computation then.\n",
    "    \"\"\"\n",
    "    # Here we  ?? \n",
    "    xt = x.T\n",
    "    for xi in xt:\n",
    "        xi[xi==-999] = np.nan\n",
    "        m = np.nanmean(xi)\n",
    "        nanidx = np.where(np.isnan(xi))\n",
    "        xi[nanidx] = m\n",
    "        \n",
    "    tx, mean, std = standardize(tX)\n",
    "    \n",
    "    return tx\n",
    "    \n",
    "tx = prepare(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-32-0470105437ad>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-0470105437ad>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "def prepareWithoutNull(tx):\n",
    "    \n",
    "    nullValue = .999\n",
    "    for i in range(0, tx): \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data entries: 250000\n",
      "Number of feature: 31\n",
      "(250000, 31)\n",
      "(250000,)\n",
      "[ 1. -1. -1. ...,  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "rows, features = tx.shape\n",
    "print('Number of data entries:', rows)\n",
    "print('Number of feature:', features)\n",
    "print(tx.shape)\n",
    "print(tx[:, 1].shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "feature1 = tx[:, 2]\n",
    "print(feature1)\n",
    "#plt.scatter(feature1, y)\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y: prediction')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in range(0, features):\n",
    "#    featureData = tx[:, f]\n",
    "#    plt.scatter(featureData, feature1)\n",
    "#    plt.xlabel('x')\n",
    "#    plt.ylabel('y: prediction')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature : \n",
    "\n",
    "    4-  > 40 =>  1\n",
    "    5-  > 6  =>  1\n",
    "    \n",
    "    1-  > 20 => -1 [10,20] => more likely to be -1\n",
    "    3-  > 20 => -1\n",
    "    21- > 10 => -1\n",
    "    26- > 22 => -1\n",
    "    29- > 13 => -1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differents learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (least_squares.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/home/audrey/Documents/Etude/MA3/PCML/project1/ML_course/projects/project1/scripts/least_squares.py\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    print(\"tx\", tx.shape)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "from least_squares import *\n",
    "from regression import *\n",
    "\n",
    "def learn_with(method, y, tx, gamma=0.1, max_iters=5, lambda_=0.1):\n",
    "    if method == 'least_squares':\n",
    "        return least_squares(y, tx)\n",
    "    \n",
    "    if method == 'least_square_GD': \n",
    "        return least_squares_GD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'least_square_SGD': \n",
    "        return least_squares_SGD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'logistic_regression': \n",
    "        return logistic_regression(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'pen_logistic_regression': \n",
    "        return pen_logisitic_regression(y, tx, lambda_, gamma, max_iters)\n",
    "    \n",
    "    if method == 'ridge_regression': \n",
    "        return ridge_regression(y, tx, lambda_)\n",
    "    \n",
    "    return least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_least_squares(y, tx):\n",
    "    l3, w3 = learn_with(\"least_square\", y, tx)\n",
    "    l2, w2 = learn_with(\"least_square_GD\", y, tx, 0.1, 50)\n",
    "    l1, w1 = learn_with(\"least_square_SGD\", y, tx, 0.1, 50)\n",
    "    print(\"SGD\")\n",
    "    print(l1)\n",
    "    print(w1)\n",
    "    print(\"GD\")\n",
    "    print(l2)\n",
    "    print(w2)\n",
    "    print(\"--\")\n",
    "    print(l3)\n",
    "    print(w3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_regression(y, tx):\n",
    "    l1, w1 = learn_with('logistic_regression', y, tx)\n",
    "    print(\"Log reg\")\n",
    "    print(l1)\n",
    "    print(w1)\n",
    "    l2, w2 = learn_with('pen_logistic_regression', y, tx)\n",
    "    print(\"Pen Log reg\")\n",
    "    print(l2)\n",
    "    print(w2)\n",
    "    l3, w3 = learn_with(\"ridge_regression\", y, tx)\n",
    "    print(\"Ridge reg\")\n",
    "    print(l3)\n",
    "    print(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(y, tx):\n",
    "    \n",
    "    loss, w = learn_with(\"least_square_GD\", y, tx)\n",
    "    \n",
    "    return loss, w\n",
    "\n",
    "#loss, weights = train(y, tx)\n",
    "compare_least_squares(y, tx)\n",
    "#compare_regression(y, tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is still doing some shit but at least it don't crash.. Maybie a problem with loss computation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn_with' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0586eecf325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"least_square_GD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn_with' is not defined"
     ]
    }
   ],
   "source": [
    "loss, weights = learn_with(\"least_square_GD\", y, tx)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n",
      "(250000, 31)\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "print(tX_test.shape)\n",
    "\n",
    "tx_Test_norm = prepare(tX_test)\n",
    "print(tx_Test_norm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-48135ec62c97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../output/out.csv'\u001b[0m \u001b[0;31m# TODO: fill in desired name of output file for submission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx_Test_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcreate_csv_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "OUTPUT_PATH = '../output/out.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tx_Test_norm)\n",
    "print(y_pred.shape)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
