{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from helpers import standardize\n",
    "\n",
    "def prepare(x):\n",
    "    \"\"\"\n",
    "    Prepare the data by standardizing and replacing unused \n",
    "    values (-999) by the mean of their columns such that they\n",
    "    don't affect the computation then.\n",
    "    \"\"\"\n",
    "    # Here we \n",
    "    xt = x.T\n",
    "    for xi in xt:\n",
    "        xi[xi==-999] = np.nan\n",
    "        m = np.nanmean(xi)\n",
    "        nanidx = np.where(np.isnan(xi))\n",
    "        xi[nanidx] = m\n",
    "        \n",
    "    tx, mean, std = standardize(tX)\n",
    "    \n",
    "    return tx\n",
    "    \n",
    "tx = prepare(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data entries: 250000\n",
      "Number of feature: 31\n",
      "(250000, 31)\n",
      "(250000,)\n"
     ]
    }
   ],
   "source": [
    "rows, features = tx.shape\n",
    "print('Number of data entries:', rows)\n",
    "print('Number of feature:', features)\n",
    "print(tx.shape)\n",
    "print(tx[:, 1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06833197  0.55250482  3.19515553 ...,  0.31931645 -0.84532397\n",
      "  0.66533608]\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams['agg.path.chunksize'] = 10000\n",
    "feature1 = tx[:, 2]\n",
    "print(feature1)\n",
    "#plt.scatter(feature1, y)\n",
    "#plt.xlabel('x')\n",
    "#plt.ylabel('y: prediction')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for f in range(0, features):\n",
    "#    featureData = tx[:, f]\n",
    "#    plt.scatter(featureData, feature1)\n",
    "#    plt.xlabel('x')\n",
    "#    plt.ylabel('y: prediction')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For feature : \n",
    "\n",
    "    4-  > 40 =>  1\n",
    "    5-  > 6  =>  1\n",
    "    \n",
    "    1-  > 20 => -1 [10,20] => more likely to be -1\n",
    "    3-  > 20 => -1\n",
    "    21- > 10 => -1\n",
    "    26- > 22 => -1\n",
    "    29- > 13 => -1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differents learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from least_squares import *\n",
    "from regression import *\n",
    "\n",
    "def learn_with(method, y, tx, gamma=0.1, max_iters=5, lambda_=0.1):\n",
    "    if method == 'least_squares':\n",
    "        return least_squares(y, tx)\n",
    "    \n",
    "    if method == 'least_square_GD': \n",
    "        return least_squares_GD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'least_square_SGD': \n",
    "        return least_squares_SGD(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'logistic_regression': \n",
    "        return logistic_regression(y, tx, gamma, max_iters)\n",
    "\n",
    "    if method == 'pen_logistic_regression': \n",
    "        return pen_logisitic_regression(y, tx, lambda_, gamma, max_iters)\n",
    "    \n",
    "    if method == 'ridge_regression': \n",
    "        return ridge_regression(y, tx, lambda_)\n",
    "    \n",
    "    return least_squares(y, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_least_squares(y, tx):\n",
    "    l3, w3 = learn_with(\"least_square\", y, tx)\n",
    "    l2, w2 = learn_with(\"least_square_GD\", y, tx, 0.1, 50)\n",
    "    l1, w1 = learn_with(\"least_square_SGD\", y, tx, 0.1, 50)\n",
    "    print(\"SGD\")\n",
    "    print(l1)\n",
    "    print(w1)\n",
    "    print(\"GD\")\n",
    "    print(l2)\n",
    "    print(w2)\n",
    "    print(\"--\")\n",
    "    print(l3)\n",
    "    print(w3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_regression(y, tx):\n",
    "    l1, w1 = learn_with('logistic_regression', y, tx)\n",
    "    print(\"Log reg\")\n",
    "    print(l1)\n",
    "    print(w1)\n",
    "    l2, w2 = learn_with('pen_logistic_regression', y, tx)\n",
    "    print(\"Pen Log reg\")\n",
    "    print(l2)\n",
    "    print(w2)\n",
    "    l3, w3 = learn_with(\"ridge_regression\", y, tx)\n",
    "    print(\"Ridge reg\")\n",
    "    print(l3)\n",
    "    print(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log reg\n",
      "93254.5058299\n",
      "[ -1.39849830e+00   1.78090752e-02  -4.40944685e-01  -4.66931976e-01\n",
      "   8.10940708e-03   3.48395499e-02   1.60262222e-01   9.56700605e-03\n",
      "   4.97598662e-01  -4.90049006e-02  -5.56885306e+02  -3.33278630e-01\n",
      "   2.01937762e-01   1.33011428e-01   1.08189475e+02  -1.36787002e-03\n",
      "  -1.40263168e-03   1.06704339e+02  -1.49117383e-03   4.37429465e-03\n",
      "   1.75242900e-01   1.54414961e-03  -8.18800511e-02   7.25449437e-02\n",
      "  -8.27775112e-02   1.09688268e-03   2.90379811e-04  -6.45691195e-02\n",
      "   2.74633823e-03  -2.99914140e-03   4.71755446e+02]\n",
      "Pen Log reg\n",
      "93264.5647878\n",
      "[ -1.39851035e+00   1.78122504e-02  -4.40988230e-01  -4.66910535e-01\n",
      "   8.07499266e-03   3.47687882e-02   1.60251047e-01   9.49104963e-03\n",
      "   4.97555280e-01  -4.90212645e-02  -1.90873585e+01  -3.33311594e-01\n",
      "   2.01911950e-01   1.33009744e-01   4.01886845e+00  -1.37514024e-03\n",
      "  -1.42422083e-03   4.14737720e+00  -1.49420016e-03   4.34613399e-03\n",
      "   1.75253304e-01   1.52960369e-03  -8.18587052e-02   7.23107928e-02\n",
      "  -8.29349723e-02   1.08604114e-03   2.64670698e-04  -6.46602711e-02\n",
      "   2.73156746e-03  -3.01109057e-03   1.61824347e+01]\n",
      "Ridge reg\n",
      "0.350013368564\n",
      "[ -2.62220000e-01  -9.03545417e-03  -1.95807087e-01  -7.76651831e-02\n",
      "   4.31464970e-02   3.97247887e-02   5.51327349e-02  -1.56271773e-02\n",
      "   1.33769916e-01  -2.84587707e-02   3.25924640e-02  -9.00124557e-02\n",
      "   1.09602638e-01   6.52223044e-02   1.26086921e-01  -1.03801472e-03\n",
      "  -1.86431259e-03   8.50482556e-02  -5.70905940e-04   2.39798751e-03\n",
      "   2.93313625e-02   1.74798353e-03  -1.06196347e-02   1.20834977e-02\n",
      "  -1.80888424e-02   2.54093812e-04   4.44767892e-04  -3.37513444e-02\n",
      "   1.28024184e-03  -1.26714025e-03  -9.50155608e-03]\n"
     ]
    }
   ],
   "source": [
    "def train(y, tx):\n",
    "    \n",
    "    loss, w = learn_with(\"least_square_GD\", y, tx)\n",
    "    \n",
    "    return loss, w\n",
    "\n",
    "#loss, weights = train(y, tx)\n",
    "#compare_least_squares(y, tx)\n",
    "compare_regression(y, tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression is still doing some shit but at least it don't crash.. Maybie a problem with loss computation ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "\n",
    "tx_test = prepare(tX_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/out.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tx_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
