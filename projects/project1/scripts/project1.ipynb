{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1.]\n",
      "[[ 1.38470e+02  5.16550e+01  9.78270e+01  2.79800e+01  9.10000e-01\n",
      "   1.24711e+02  2.66600e+00  3.06400e+00  4.19280e+01  1.97760e+02\n",
      "   1.58200e+00  1.39600e+00  2.00000e-01  3.26380e+01  1.01700e+00\n",
      "   3.81000e-01  5.16260e+01  2.27300e+00 -2.41400e+00  1.68240e+01\n",
      "  -2.77000e-01  2.58733e+02  2.00000e+00  6.74350e+01  2.15000e+00\n",
      "   4.44000e-01  4.60620e+01  1.24000e+00 -2.47500e+00  1.13497e+02]\n",
      " [ 1.60937e+02  6.87680e+01  1.03235e+02  4.81460e+01 -9.99000e+02\n",
      "  -9.99000e+02 -9.99000e+02  3.47300e+00  2.07800e+00  1.25157e+02\n",
      "   8.79000e-01  1.41400e+00 -9.99000e+02  4.20140e+01  2.03900e+00\n",
      "  -3.01100e+00  3.69180e+01  5.01000e-01  1.03000e-01  4.47040e+01\n",
      "  -1.91600e+00  1.64546e+02  1.00000e+00  4.62260e+01  7.25000e-01\n",
      "   1.15800e+00 -9.99000e+02 -9.99000e+02 -9.99000e+02  4.62260e+01]\n",
      " [-9.99000e+02  1.62172e+02  1.25953e+02  3.56350e+01 -9.99000e+02\n",
      "  -9.99000e+02 -9.99000e+02  3.14800e+00  9.33600e+00  1.97814e+02\n",
      "   3.77600e+00  1.41400e+00 -9.99000e+02  3.21540e+01 -7.05000e-01\n",
      "  -2.09300e+00  1.21409e+02 -9.53000e-01  1.05200e+00  5.42830e+01\n",
      "  -2.18600e+00  2.60414e+02  1.00000e+00  4.42510e+01  2.05300e+00\n",
      "  -2.02800e+00 -9.99000e+02 -9.99000e+02 -9.99000e+02  4.42510e+01]]\n",
      "[100000 100001 100002]\n"
     ]
    }
   ],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "y.shape, tX.shape, ids.shape\n",
    "print(y[0:3])\n",
    "print(tX[0:3])\n",
    "print(ids[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138.47   51.655  97.827 ...   1.24   -2.475 113.497]\n",
      " [160.937  68.768 103.235 ...   0.      0.     46.226]\n",
      " [  0.    162.172 125.953 ...   0.      0.     44.251]\n",
      " ...\n",
      " [105.457  60.526  75.839 ...   0.      0.     41.992]\n",
      " [ 94.951  19.362  68.812 ...   0.      0.      0.   ]\n",
      " [  0.     72.756  70.831 ...   0.      0.      0.   ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tX_standardized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-27474c449a98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtX_standardized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtX_std\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX_standardized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX_standardized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tX_standardized' is not defined"
     ]
    }
   ],
   "source": [
    "tX_no_outliers = tX.copy()\n",
    "tX_no_outliers[tX_no_outliers == -999] = 0\n",
    "print(tX_no_outliers)\n",
    "\n",
    "\n",
    "tX_standardized, tX_mean, tX_std= standardize(tX_standardized)\n",
    "print(tX_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.88857241e-02, -5.91053272e-01, -5.46678636e-01, -3.48875183e-02,\n",
       "        -8.28596722e-01,  3.57637058e-02, -7.11591047e-01,  2.88153592e+01,\n",
       "        -6.61943439e-03,  2.29096097e+01, -1.83948731e+01,  8.50945445e+00,\n",
       "         2.84940447e+01, -2.22203109e+01, -7.41586750e-02, -4.44509261e-02,\n",
       "        -2.18359691e+01, -1.83714253e-02,  1.13074425e-01,  2.57779664e-01,\n",
       "         4.01629576e-02, -3.92161700e-02,  1.22475267e+00,  2.14143727e-01,\n",
       "         2.99820109e-02,  9.53216282e-04,  9.66557697e-02,  9.95320306e-02,\n",
       "        -1.63590161e-01, -2.31510175e+01]), 0.3390172811873623)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_initial = np.zeros(tX_standardized.shape[1])\n",
    "#[weights, loss]=least_squares_GD(y, tX, w_initial, 10, 0.000001)\n",
    "[weights, loss]= least_squares(y, tX_standardized)\n",
    "#[weights, loss] = least_squares_SGD(y, tX, w_initial, 1000, 0.00000001)\n",
    "weights, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/pred.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
