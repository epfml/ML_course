{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>r44_c1</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>r61_c1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>r67_c1</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>r72_c1</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>r86_c1</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Prediction user item\n",
       "0  r44_c1           4   44    1\n",
       "1  r61_c1           3   61    1\n",
       "2  r67_c1           4   67    1\n",
       "3  r72_c1           3   72    1\n",
       "4  r86_c1           5   86    1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets/data_train.csv\")\n",
    "\n",
    "df[[\"user\", \"item\"]] = df.Id.str.split(\"_\", expand=True)\n",
    "\n",
    "df.user = df.user.str.replace(\"r\", \"\")\n",
    "df.item = df.item.str.replace(\"c\", \"\")\n",
    "\n",
    "#########\n",
    "df2 = pd.read_csv(\"Datasets/sample_submission.csv\")\n",
    "\n",
    "df2[[\"user\", \"item\"]] = df2.Id.str.split(\"_\", expand=True)\n",
    "\n",
    "df2.user = df2.user.str.replace(\"r\", \"\")\n",
    "df2.item = df2.item.str.replace(\"c\", \"\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1,5)) \n",
    "data = Dataset.load_from_df(df[[\"user\",\"item\",\"Prediction\"]], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD # importer ici les algo qu'on testera\n",
    "from surprise import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans la cell suivante, on va créer un \"model selection\" qui se base sur grid search cv. Ce dernier prend des paramètres et pourrait prendre plusieurs algos, a tester chacun selon les paramètres etc etc, mais ce n'est qu'une définition de model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005], 'reg_all': [0.4, 0.6]} #ici il va falloir apprendre et définir les paramtères à tester\n",
    "\n",
    "gs = model_selection.GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)  #définition du model selon les paramètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est dans la celle suivante que se font actuellement les calculs de chaque algo défini au dessus, avec les paramètres etc\n",
    "c'est normalement cette celle qui prendra mille an a tourner car elle calculera tout pour nous ressortir ce qu'il y a de mieux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(data) # les calculs se font actuellement ici "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principe de SKLearn et Surprise qui est basé sur le premier:\n",
    "* définition d'un test model à travers model_selection.gridsearchcv\n",
    "* testmodel.fit qui va tester les model et paramètres pour retourner ce qu'il y a de mieux\n",
    "* algorithm = testmodel.best_estimator[\"type de erreur choisi\"] nous donne le meilleur algo selon les meilleur paramtère\n",
    "* algo.fit(data)\n",
    "* algo.estimate(data a tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split0_test_rmse</th>\n",
       "      <th>split1_test_rmse</th>\n",
       "      <th>split2_test_rmse</th>\n",
       "      <th>mean_test_rmse</th>\n",
       "      <th>std_test_rmse</th>\n",
       "      <th>rank_test_rmse</th>\n",
       "      <th>split0_test_mae</th>\n",
       "      <th>split1_test_mae</th>\n",
       "      <th>split2_test_mae</th>\n",
       "      <th>mean_test_mae</th>\n",
       "      <th>std_test_mae</th>\n",
       "      <th>rank_test_mae</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_test_time</th>\n",
       "      <th>std_test_time</th>\n",
       "      <th>params</th>\n",
       "      <th>param_n_epochs</th>\n",
       "      <th>param_lr_all</th>\n",
       "      <th>param_reg_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.016604</td>\n",
       "      <td>1.019065</td>\n",
       "      <td>1.019457</td>\n",
       "      <td>1.018375</td>\n",
       "      <td>0.001263</td>\n",
       "      <td>4</td>\n",
       "      <td>0.836175</td>\n",
       "      <td>0.838323</td>\n",
       "      <td>0.837787</td>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>2</td>\n",
       "      <td>9.873740</td>\n",
       "      <td>0.218786</td>\n",
       "      <td>4.438072</td>\n",
       "      <td>0.101825</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.023789</td>\n",
       "      <td>1.026245</td>\n",
       "      <td>1.026634</td>\n",
       "      <td>1.025556</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>7</td>\n",
       "      <td>0.843743</td>\n",
       "      <td>0.846079</td>\n",
       "      <td>0.845410</td>\n",
       "      <td>0.845078</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>6</td>\n",
       "      <td>9.416066</td>\n",
       "      <td>0.167271</td>\n",
       "      <td>4.617349</td>\n",
       "      <td>0.831556</td>\n",
       "      <td>{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
       "0          1.016604          1.019065          1.019457        1.018375   \n",
       "1          1.023789          1.026245          1.026634        1.025556   \n",
       "\n",
       "   std_test_rmse  rank_test_rmse  split0_test_mae  split1_test_mae  \\\n",
       "0       0.001263               4         0.836175         0.838323   \n",
       "1       0.001260               7         0.843743         0.846079   \n",
       "\n",
       "   split2_test_mae  mean_test_mae  std_test_mae  rank_test_mae  mean_fit_time  \\\n",
       "0         0.837787       0.837428      0.000913              2       9.873740   \n",
       "1         0.845410       0.845078      0.000982              6       9.416066   \n",
       "\n",
       "   std_fit_time  mean_test_time  std_test_time  \\\n",
       "0      0.218786        4.438072       0.101825   \n",
       "1      0.167271        4.617349       0.831556   \n",
       "\n",
       "                                             params  param_n_epochs  \\\n",
       "0  {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.4}               5   \n",
       "1  {'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}               5   \n",
       "\n",
       "   param_lr_all  param_reg_all  \n",
       "0         0.002            0.4  \n",
       "1         0.002            0.6  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results).head(2) #enlever head pour tout afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}, 'mae': {'n_epochs': 10, 'lr_all': 0.002, 'reg_all': 0.4}}\n",
      "{'rmse': 1.0147312871491405, 'mae': 0.8334400451350668}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_params )\n",
    "print(gs.best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = gs.best_estimator[\"mae\"] #choix de l'algo selon l'erreur, touuuut inclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f8a4672f190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.fit(data.build_full_trainset()) # ici on va train notre algo sur le dataset complet, sans cv car les paramètres sont optimaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La différence entre algo.predict et algo.estimate est que predict devrait être utilisé sur des valeurs que l'on connait d'avance, par exemple si on sait que le user 5 pour le film 12 a voté 3, on peut rentrer ces valeurs et voir \"l'erreur\"\n",
    "algo.estimate fait littéralement ce qu'on veut pour le projet, c'est à dire estimer. Pas à 100% sur sur de ça ici mais c'est ce qui me parait le plus juste. Pour l'instant on boucle sur algo.estimate mais il y a peut etre mieux à faire \n",
    "il faudra round la valeur la remettre dans le pred.csv etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.175039848821002"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo.estimate(37,1) #premier à tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessous, ce qu'on avait testé au début, on peut définir un algo ici SVD avec ses paramètres de bases, faire un model_selection.cross_validate dessus mais qui \"ne sert a rien\" car il faudrait comparer ça avec la même fonction mais pour d'autres algos\n",
    "finalement on fit direct notre data, et on estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([1.03829264, 1.03510797]),\n",
       " 'test_mae': array([0.83187162, 0.82874481]),\n",
       " 'fit_time': (27.694921255111694, 28.023682832717896),\n",
       " 'test_time': (8.076480865478516, 5.6071672439575195)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_algo = SVD()\n",
    "model_selection.cross_validate(temp_algo, data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7f8a466df090>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_algo.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=37, iid=1, r_ui=None, est=3.8572805008190647, details={'was_impossible': False})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_algo.predict(37,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1280121789331625"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_algo.estimate(37,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
