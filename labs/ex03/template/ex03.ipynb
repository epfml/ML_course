{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import python files from another directory\n",
    "In order to reuse code written in .py files you need to import them.\n",
    "If they are from a distant folder, rather than copy-paste it into the current folder, you can write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../ex02/template\") # This goes up twice in the directories tree (hence in labs)\n",
    "                                       # then goes down to ex02/template where your files from lab 2 are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can now import your desired files, for example, we can import grid_search.py with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100.  -25.   50.  125.  200.] [-150.  -75.    0.   75.  150.]\n"
     ]
    }
   ],
   "source": [
    "import grid_search        # You then need to call your functions using grid_search.function_name()\n",
    "import grid_search as gs  # You then need to call your functions using gs.function_name()\n",
    "from grid_search import * # You can call any functions of the file with function_name()\n",
    "\n",
    "# Let's try to call generate_w from grid_search.py:\n",
    "w0, w1 = generate_w(5)\n",
    "print(w0, w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we are now able to call functions from the grid_search.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from gradient_descent import *\n",
    "from test_utils import test\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Least squares and linear basis functions models\n",
    "## 1.1 Least squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def least_squares(y, tx):\n",
    "    \"\"\"Calculate the least squares solution.\n",
    "       returns mse, and optimal weights.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array of shape (N,), N is the number of samples.\n",
    "        tx: numpy array of shape (N,D), D is the number of features.\n",
    "    \n",
    "    Returns:\n",
    "        w: optimal weights, numpy array of shape(D,), D is the number of features.\n",
    "        mse: scalar.\n",
    "\n",
    "    >>> least_squares(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]))\n",
    "    (array([ 0.21212121, -0.12121212]), 8.666684749742561e-33)\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least squares: \n",
    "    w=np.linalg.solve(tx.T@tx,tx.T@y)\n",
    "    mse=np.linalg.norm(y-tx@w) #probablement erreur\n",
    "    return w,mse\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can test your implementation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ The are some issues with your implementation of `least_squares`:\n",
      "**********************************************************************\n",
      "File \"__main__\", line 13, in least_squares\n",
      "Failed example:\n",
      "    least_squares(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]))\n",
      "Expected:\n",
      "    (array([ 0.21212121, -0.12121212]), 8.666684749742561e-33)\n",
      "Got:\n",
      "    (array([ 0.21212121, -0.12121212]), 3.466673899897025e-32)\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "test(least_squares)\n",
    "# NB:\n",
    "# \n",
    "# Due to precision issues, \n",
    "# the output might not be exactly the same \n",
    "# even if you have implemented the right code.\n",
    "#\n",
    "# For example, the mse output expected to be\n",
    "# 8.666684749742561e-33,\n",
    "# but you might get some other small number\n",
    "# close to zero.\n",
    "#\n",
    "# In this case,\n",
    "# Failing the test doesn't necessarily means\n",
    "# your implementation is wrong.:) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "Here we will reuse the dataset `height_weight_genders.csv` from previous exercise section to check the correctness of your implementation. Please compare it with your previous result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_your_least_squares():\n",
    "    \"\"\"\n",
    "    # this code should compare the optimal weights obtained \n",
    "    # by least squares vs. grid search\n",
    "    \"\"\"\n",
    "    height, weight, gender = load_data_from_ex02(sub_sample=False, add_outlier=False)\n",
    "    x, mean_x, std_x = standardize(height)\n",
    "    y, tx = build_model_data(x, weight)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # least square or grid search: \n",
    "    w_least,mse_least=least_squares(y,tx)\n",
    "    loss_grad,w_grad=gradient_descent(y, tx, [0,0], 50, 0.7)\n",
    "\n",
    "    # this code should compare the optimal weights obtained \n",
    "    # by least squares vs. grid search\n",
    "    print(\"least: \"+str(w_least)+\" loss: \"+str(mse_least))\n",
    "    print('grad: '+str(w_grad[-1])+\" loss: \"+str(loss_grad[-1]))\n",
    "    # ***************************************************\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "least: [73.293922   13.47971243] loss: 554.7231357863014\n",
      "grad: [73.293922   13.47971243] loss: 15.385887868829453\n"
     ]
    }
   ],
   "source": [
    "test_your_least_squares()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Least squares with a linear basis function model\n",
    "Start from this section, we will use the dataset `dataEx3.csv`.\n",
    "\n",
    "### Implement polynomial basis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x (50,)\n",
      "shape of y (50,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x, y = load_data()\n",
    "print(\"shape of x {}\".format(x.shape))\n",
    "print(\"shape of y {}\".format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,d+1)\n",
    "        \n",
    "    >>> build_poly(np.array([0.0, 1.5]), 2)\n",
    "    array([[1.  , 0.  , 0.  ],\n",
    "           [1.  , 1.5 , 2.25]])\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # polynomial basis function: \n",
    "    Phi=np.array([[xx**j for j in range(0,degree+1)]for xx in x  ])\n",
    "    # this function should return the matrix formed\n",
    "    # by applying the polynomial basis to the input data\n",
    "    # ***************************************************\n",
    "    return Phi\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `build_poly` passed 1 tests.\n"
     ]
    }
   ],
   "source": [
    "test(build_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with polynomial regression. Note that we will use your implemented function `compute_mse`. Please copy and paste your implementation from exercise02."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import sqrt\n",
    "from plots import *\n",
    "def polynomial_regression():\n",
    "    \"\"\"Constructing the polynomial basis function expansion of the data,\n",
    "       and then running least squares regression.\"\"\"\n",
    "    # define parameters\n",
    "    degrees = [1, 3, 7, 12]\n",
    "    \n",
    "    # define the structure of the figure\n",
    "    num_row = 2\n",
    "    num_col = 2\n",
    "    f, axs = plt.subplots(num_row, num_col)\n",
    "\n",
    "    for ind, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # form the data to do polynomial regression.: TODO\n",
    "        x=build_poly(x,degree)\n",
    "        # ***************************************************\n",
    "        \n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # least square and calculate RMSE: TODO\n",
    "        weights,mse=least_squares(y,x)\n",
    "        rmse=sqrt(2*mse)\n",
    "        # ***************************************************\n",
    "        \n",
    "\n",
    "        print(\"Processing {i}th experiment, degree={d}, rmse={loss}\".format(\n",
    "              i=ind + 1, d=degree, loss=rmse))\n",
    "        # plot fit\n",
    "        plot_fitted_curve(\n",
    "            y, x, weights, degree, axs[ind // num_col][ind % num_col])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1th experiment, degree=1, rmse=(2.583279991751105+0j)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fosmo\\OneDrive\\Documents\\GitHub\\ML\\labs\\ex03\\template\\ex03.ipynb Cellule 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m polynomial_regression(x,y)\n",
      "\u001b[1;32mc:\\Users\\fosmo\\OneDrive\\Documents\\GitHub\\ML\\labs\\ex03\\template\\ex03.ipynb Cellule 22\u001b[0m in \u001b[0;36mpolynomial_regression\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcessing \u001b[39m\u001b[39m{i}\u001b[39;00m\u001b[39mth experiment, degree=\u001b[39m\u001b[39m{d}\u001b[39;00m\u001b[39m, rmse=\u001b[39m\u001b[39m{loss}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m           i\u001b[39m=\u001b[39mind \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, d\u001b[39m=\u001b[39mdegree, loss\u001b[39m=\u001b[39mrmse))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m# plot fit\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     plot_fitted_curve(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         y, x, weights, degree, axs[ind \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m num_col][ind \u001b[39m%\u001b[39;49m num_col])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m plt\u001b[39m.\u001b[39mtight_layout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/fosmo/OneDrive/Documents/GitHub/ML/labs/ex03/template/ex03.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\fosmo\\OneDrive\\Documents\\GitHub\\ML\\labs\\ex03\\template\\plots.py:10\u001b[0m, in \u001b[0;36mplot_fitted_curve\u001b[1;34m(y, x, weights, degree, ax)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_fitted_curve\u001b[39m(y, x, weights, degree, ax):\n\u001b[0;32m      9\u001b[0m     \u001b[39m\"\"\"plot the fitted curve.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     ax\u001b[39m.\u001b[39;49mscatter(x, y, color\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mb\u001b[39;49m\u001b[39m'\u001b[39;49m, s\u001b[39m=\u001b[39;49m\u001b[39m12\u001b[39;49m, facecolors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m, edgecolors\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m     xvals \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mmin\u001b[39m(x) \u001b[39m-\u001b[39m \u001b[39m0.1\u001b[39m, \u001b[39mmax\u001b[39m(x) \u001b[39m+\u001b[39m \u001b[39m0.1\u001b[39m, \u001b[39m0.1\u001b[39m)\n\u001b[0;32m     12\u001b[0m     tx \u001b[39m=\u001b[39m build_poly(xvals, degree)\n",
      "File \u001b[1;32md:\\logiciel\\miniconda\\lib\\site-packages\\matplotlib\\__init__.py:1361\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1359\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1360\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1361\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1363\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1364\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1365\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32md:\\logiciel\\miniconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:4498\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4496\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mravel(y)\n\u001b[0;32m   4497\u001b[0m \u001b[39mif\u001b[39;00m x\u001b[39m.\u001b[39msize \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39msize:\n\u001b[1;32m-> 4498\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mx and y must be the same size\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4500\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4501\u001b[0m     s \u001b[39m=\u001b[39m (\u001b[39m20\u001b[39m \u001b[39mif\u001b[39;00m rcParams[\u001b[39m'\u001b[39m\u001b[39m_internal.classic_mode\u001b[39m\u001b[39m'\u001b[39m] \u001b[39melse\u001b[39;00m\n\u001b[0;32m   4502\u001b[0m          rcParams[\u001b[39m'\u001b[39m\u001b[39mlines.markersize\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2.0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "polynomial_regression(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your results should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](visualize_polynomial_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Evaluating model predication performance\n",
    "\n",
    "Let us show the train and test splits for various polynomial degrees. First of all, please fill in the function `split_data()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"\n",
    "    split the dataset based on the split ratio. If ratio is 0.8 \n",
    "    you will have 80% of your data set dedicated to training \n",
    "    and the rest dedicated to testing. If ratio times the number of samples is not round\n",
    "    you can use np.floor. Also check the documentation for np.random.permutation,\n",
    "    it could be useful.\n",
    "    \n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        y: numpy array of shape (N,).\n",
    "        ratio: scalar in [0,1]\n",
    "        seed: integer.\n",
    "        \n",
    "    Returns:\n",
    "        x_tr: numpy array containing the train data.\n",
    "        x_te: numpy array containing the test data.\n",
    "        y_tr: numpy array containing the train labels.\n",
    "        y_te: numpy array containing the test labels.\n",
    "        \n",
    "    >>> split_data(np.arange(13), np.arange(13), 0.8, 1)\n",
    "    (array([ 2,  3,  4, 10,  1,  6,  0,  7, 12,  9]), array([ 8, 11,  5]), array([ 2,  3,  4, 10,  1,  6,  0,  7, 12,  9]), array([ 8, 11,  5]))\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data based on the given ratio: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(split_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, test your `split_data` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"polynomial regression with different split ratios and different degrees.\n",
    "    \n",
    "    Returns:\n",
    "      x_tr: numpy array\n",
    "      x_te: numpy array\n",
    "      y_tr: numpy array\n",
    "      y_te: numpy array\n",
    "      weights: weights from the least squares optimization\"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate weight through least square: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate RMSE for train and test data,\n",
    "    # and store them in rmse_tr and rmse_te respectively: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    print(\"proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "          p=ratio, d=degree, tr=rmse_tr, te=rmse_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demo time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 6\n",
    "degrees = [1, 3, 7, 12]\n",
    "split_ratios = [0.9, 0.7, 0.5, 0.1]\n",
    "\n",
    "# define the structure of the figure\n",
    "num_row = 4\n",
    "num_col = 4\n",
    "axs = plt.subplots(num_row, num_col, figsize=(20,8))[1]\n",
    "\n",
    "for ind, split_ratio in enumerate(split_ratios):\n",
    "    for ind_d, degree in enumerate(degrees):\n",
    "        x_tr, x_te, y_tr, y_te, w = train_test_split_demo(x, y, degree, split_ratio, seed)\n",
    "        plot_fitted_curve(\n",
    "            y_tr, x_tr, w, degree, axs[ind_d][ind % num_col])\n",
    "        axs[ind_d][ind].set_title(f'Degree: {degree}, Split {split_ratio}')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your graph should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](split_demo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "Please fill in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    \"\"\"implement ridge regression.\n",
    "    \n",
    "    Args:\n",
    "        y: numpy array of shape (N,), N is the number of samples.\n",
    "        tx: numpy array of shape (N,D), D is the number of features.\n",
    "        lambda_: scalar.\n",
    "    \n",
    "    Returns:\n",
    "        w: optimal weights, numpy array of shape(D,), D is the number of features.\n",
    "\n",
    "    \n",
    "\n",
    "    >>> ridge_regression(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]), 0)\n",
    "    array([ 0.21212121, -0.12121212])\n",
    "    >>> ridge_regression(np.array([0.1,0.2]), np.array([[2.3, 3.2], [1., 0.1]]), 1)\n",
    "    array([0.03947092, 0.00319628])\n",
    "    \"\"\"\n",
    "    w=np.linalg.solve(tx.T@tx+2*y.shape[0]*lambda_*np.eye(tx.shape[1]),tx.T@y)\n",
    "    return w\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `ridge_regression` passed 2 tests.\n"
     ]
    }
   ],
   "source": [
    "test(ridge_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-5, 0, 15)\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # split the data, and return train and test data: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form train and test data with polynomial basis function: TODO\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError\n",
    "\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    for ind, lambda_ in enumerate(lambdas):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ridge regression with a given lambda\n",
    "        # ***************************************************\n",
    "        raise NotImplementedError\n",
    "        print(\"proportion={p}, degree={d}, lambda={l:.3f}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "               p=ratio, d=degree, l=lambda_, tr=rmse_tr[ind], te=rmse_te[ind]))\n",
    "    plot_train_test(rmse_tr, rmse_te, lambdas, degree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Demo time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 56\n",
    "degree = 7\n",
    "split_ratio = 0.5\n",
    "ridge_regression_demo(x, y, degree, split_ratio, seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your plot should look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](ridge_regression.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "421272cbf3939b835604506f9ba76b0a3d4ecc71622f2685fa1b29b90be7a285"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
